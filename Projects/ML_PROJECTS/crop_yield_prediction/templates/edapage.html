<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>EDA</title>
    <link rel="stylesheet" href="../static/css/styleseda.css">
</head>
<body>
    <section class="eda-page">
        <div class="main-container">
        <img src="https://cdn.builder.io/api/v1/image/assets/TEMP/b337627b4f1a3802327717098d691f8ec42fff16ee32b313522c658621e111fd?placeholderIfAbsent=true&apiKey=3b2a7142125141cc827fb1ead6ce9c1a" alt="" class="background-image" />
        <nav class="nav-section">
            <ul class="nav-items">
            <li class="nav-item"><a href="/">HOME</a></li>
            <li class="nav-item"><a href="/dataset">DATASET</a></li>
            <li class="nav-item nav-item-active"><a href="/eda">EDA</a></li>
            <li class="nav-item"><a href="/model">MODEL</a></li>
            </ul>
        </nav>
        <article class="insights-container">
            <h2 class="visually-hidden">EDA Insights</h2>
            <p class="insights-text">
            EDA INSIGHTS: <br />
            1. The dataset has 777 rows and 18 columns. <br />
            2. All columns of the dataset are numerical columns. <br />
            3. None of the columns have null values. <br />
            4. Columns like clonesize, honeybee, andrena and osmia at a glance seemed to have constant values but have actually 6, 7, 10, 12, 12 unique values in the dataset respectively. <br />
            5. By using boxplots we can observe that the columns of honeybee, bumbles , andrena and osmia have outliers that were removed reducing number of rows from 777 to 760. <br />
            </p>
            <div class="charts-container">
            <div class="charts-row">
                <div class="chart-column">
                <img src="../static/images/v37_60.png" alt="Chart showing data distribution" class="chart-image" />
                </div>
                <div class="chart-column">
                <img src="../static/images/v37_61.png" alt="Chart showing outlier removal" class="chart-image" />
                </div>
            </div>
            </div>
        <p class="insights-text">
            6. Overall amount of crop yield lies between the range of 5600-6399.
            <div class="charts-row">
                <div class="chart-column">
                <img src="../static/images/v37_63.png" alt="Chart showing data distribution" class="chart-image" />
                </div>
            </div>
        </p>
        <p class="insights-text">
            7. Overall clonesize 12.5 gives highest average yield.
            <div class="charts-row">
                <div class="chart-column">
                <img src="../static/images/v37_65.png" alt="Chart showing data distribution" class="chart-image" />
                </div>
            </div>
        </p>
        <p class="insights-text">
            7. Overall clonesize 12.5 gives highest average yield.
            <div class="charts-row">
                <div class="chart-column">
                <img src="../static/images/v37_65.png" alt="Chart showing data distribution" class="chart-image" />
                </div>
            </div>
        </p>
        <p class="insights-text">
            8. The natural factors such as temperature and rain donâ€™t seem to affect the bees. This can be because the data was actually created artificially from a simulation environment and not taken from real life.
            <div class="charts-row">
                <div class="chart-column">
                <img src="../static/images/v37_67.png" alt="Chart showing data distribution" class="chart-image" id="hash-chart"/>
                </div>
            </div>
        </p>
        <p class="insights-text">
            9. There is no discernable relation between the independent columns and that of yield therfore we cant use these columns to predict the target yield directly but a certain combination might work out.
            <div class="charts-row">
                <div class="chart-column">
                <img src="../static/images/v37_69.png" alt="Chart showing data distribution" class="chart-image" id="hash-chart"/>
                </div>
            </div>
        </p>
        <p class="insights-text">
            10. To facilitate in feature engineering and selection we find the correlation of each column with respect to the target yield.
            <div class="charts-row">
                <div class="chart-column">
                <img src="../static/images/v37_71.png" alt="Chart showing data distribution" class="chart-image" id="hash-chart2"/>
                </div>
            </div>
        </p>
        <p class="insights-text">
            It seems that:<br/>
            1. clonesize, RainingDays and AverageRainingDays have highest magnitude of -ve correlation with yield.<br/>
            2. MaxOFUpperTRange, MinOfUpperTRange, AverageOfUpperTRange, MaxOfLowerTRange, MinOFLowerTRange and AverageOfLowerTRange all seem to have almost same magnitude of correlation with yield.<br/>
            3. bumbles, andrena and osmia have positive correlation with yield.<br/>
            4. fruitset, fruitmass and seeds are all highly positively correlated with yield.<br/>
        </p>
        <p class="insights-text" id="spacer">
            11. Using a heatmap we will display the correlation of every column with each other to facilitate in feature selection and engineering.
            <div class="charts-row">
                <div class="chart-column">
                <img src="../static/images/v37_74.png" alt="Chart showing data distribution" class="chart-image" id="hash-chart2"/>
                </div>
            </div>
        </p>
        <p class="insights-text">
            From the above matrix we get that the columns MaxOFUpperTRange, MinOfUpperTRange, AverageOfUpperTRange, MaxOfLowerTRange, MinOFLowerTRange and AverageOfLowerTRange are highly correlated with each other.
        </p>
        <p class="insights-text" id="spacer">
            12. Now as a matter of fact we know that the columns fruitset, fruitmass and seeds are direct results of yield column so we cannot use them as they possess a highy linear relationship with the yield column but are also highly dependent on yield.
            <div class="charts-row">
                <div class="chart-column">
                <img src="../static/images/v37_77.png" alt="Chart showing data distribution" class="chart-image" id="hash-chart"/>
                </div>
            </div>
        </p>
        <p class="insights-text">
            13. An extra column of mean_temp maybe observed in the above bar plot for plotting the correlation of columns with respect to yield. The values for that column mean_temp were calculated by using the formula for each row:
            <br/>
            <br/>
            mean_temp = (MaxOFUpperTRange+MinOfUpperTRange+MaxOfLowerTRange+MinOFLowerTRange)/4
            <br/>
            <br/>
            Also since it has the same correlation value of -0.18 with yield as every other temperature column we can reduce the dimensionality and select the mean_temp column to replace the other columns of temperature.
        </p>
        <p class="insights-text"  id="spacer">
            14. Finally after trying out multiple combinations the following combination provides the best results.
            <br/>
            <br/>
            Columns used: clonesize, honeybee, bumbles, andrena, osmia, mean_temp,  AverageRainingDays
            <br/>
            <br/>
            The follwing graph shows the data distribution of the columns with respect to yield and the best fit line for the data.
            <br/>
            <br/>
            Eqn for best fit line: y = -494.03*x + 11387.39
            <div class="charts-row">
                <div class="chart-column">
                <img src="../static/images/v37_80.png" alt="Chart showing data distribution" class="chart-image" id="hash-chart"/>
                </div>
            </div>
        </p>
        <p class="insights-text">
            15. Also via experiments when the mean of the median aggregates were considered for the above obsierved values as most values seem to be localised at certain values of x-axis the model was performing better. However such change didnt affect the best fit line.
            <br/>
            Eqn for best fit line: y = -494.03*x + 11387.39
            <div class="charts-row">
                <div class="chart-column">
                <img src="../static/images/v37_82.png" alt="Chart showing data distribution" class="chart-image"/>
                </div>
            </div>
        </p>
        <p class="insights-text">
            15. Also via experiments comparing multiple different models XgBoost performs the best out of them all.
            <br/><br/>
            <div>
                <table border="2" class="dataframe" style="border-radius: 3px;">
                    <thead>
                        <tr style="text-align: right;">
                            <th></th>
                            <th>training MSE</th>
                            <th>training RMSE</th>
                            <th>training mean cv score</th>
                            <th>training r2 score</th>
                            <th>slope<br/>(actual)</th>
                            <th>slope<br/>(predicted)</th>
                            <th>intercept<br/>(actual)</th>
                            <th>intercept<br/>(predicted)</th>
                            <th>testing MSE</th>
                            <th>testing RMSE</th>
                            <th>testing mean cv score</th>
                            <th>testing r2 score</th>
                            <th>slope<br/>(actual)</th>
                            <th>slope<br/>(predicted)</th>
                            <th>intercept<br/>(actual)</th>
                            <th>intercept<br/>(predicted)</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <th>LINEAR <br/>REGRESSOR</th>
                            <td>367237.309</td>
                            <td>606.001</td>
                            <td>0.77845</td>
                            <td>0.79666</td>
                            <td>-490.6971</td>
                            <td>-490.6971</td>
                            <td>11347.0777</td>
                            <td>11347.0777</td>
                            <td>268269.89693</td>
                            <td>517.94777</td>
                            <td>0.77845</td>
                            <td>0.846476</td>
                            <td>-502.0819</td>
                            <td>-461.9213</td>
                            <td>11484.1371</td>
                            <td>11062.4255</td>
                        </tr>
                        <tr>
                            <th>DECISION TREE REGRESSOR</th>
                            <td>218988.4606</td>
                            <td>467.962</td>
                            <td>0.82945</td>
                            <td>0.87874</td>
                            <td>-490.6971</td>
                            <td>-462.1716</td>
                            <td>11347.0777</td>
                            <td>11038.3504</td>
                            <td>206779.105</td>
                            <td>454.7297</td>
                            <td>0.82945</td>
                            <td>0.88166</td>
                            <td>-502.0819</td>
                            <td>-481.8332</td>
                            <td>11484.1371</td>
                            <td>11290.9617</td>
                        </tr>
                        <tr>
                            <th>RANDOM FOREST REGRESSOR</th>
                            <td>408838.707</td>
                            <td>639.405</td>
                            <td>0.73833</td>
                            <td>0.77362</td>
                            <td>-490.6971</td>
                            <td>-442.5235</td>
                            <td>11347.0777</td>
                            <td>10835.221</td>
                            <td>397300.9355</td>
                            <td>630.3181</td>
                            <td>0.73833</td>
                            <td>0.77263</td>
                            <td>-502.0819</td>
                            <td>-457.3526</td>
                            <td>11484.137</td>
                            <td>11043.2286</td>
                        </tr>
                        <tr>
                            <th>K-NEIGHBOURS REGRESSOR</th>
                            <td>288670.4271</td>
                            <td>537.2806</td>
                            <td>0.79462</td>
                            <td>0.84016</td>
                            <td>-490.6971</td>
                            <td>-471.8733</td>
                            <td>11347.0777</td>
                            <td>11233.8378</td>
                            <td>345149.0742</td>
                            <td>587.4939</td>
                            <td>0.79462</td>
                            <td>0.80248</td>
                            <td>-502.0819</td>
                            <td>-485.1274</td>
                            <td>11484.137</td>
                            <td>11414.3443</td>
                        </tr>
                        <tr>
                            <th>SUPPORT VECTOR REGRESSOR</th>
                            <td>1294797.562</td>
                            <td>1137.8917</td>
                            <td>0.2461</td>
                            <td>0.28306</td>
                            <td>-490.6971</td>
                            <td>-423.2449</td>
                            <td>11347.0777</td>
                            <td>10781.6404</td>
                            <td>1127827.0579</td>
                            <td>1061.992</td>
                            <td>0.2461</td>
                            <td>0.35457</td>
                            <td>-502.0819</td>
                            <td>-422.188</td>
                            <td>11484.137</td>
                            <td>10747.406</td>
                        </tr>
                        <tr>
                            <th>GRADIENT BOOSTING REGRESSOR</th>
                            <td>34517.9289</td>
                            <td>185.79</td>
                            <td>0.97068</td>
                            <td>0.9809</td>
                            <td>-490.6971</td>
                            <td>-487.1509</td>
                            <td>11347.0777</td>
                            <td>11313.8726</td>
                            <td>44719.0446</td>
                            <td>211.4688</td>
                            <td>0.970677</td>
                            <td>0.97441</td>
                            <td>-502.0819</td>
                            <td>-488.933</td>
                            <td>11484.1371</td>
                            <td>11366.2348</td>
                        </tr>
                        <tr>
                            <th>BAGGING <br/>REGRESSOR</th>
                            <td>372561.1474</td>
                            <td>610.3779</td>
                            <td>0.76753</td>
                            <td>0.7937</td>
                            <td>-490.6971</td>
                            <td>-421.428</td>
                            <td>11347.0777</td>
                            <td>10623.545</td>
                            <td>349033.6856</td>
                            <td>590.7907</td>
                            <td>0.76753</td>
                            <td>0.80026</td>
                            <td>-502.0819</td>
                            <td>-436.70234</td>
                            <td>11484.1371</td>
                            <td>10837.481</td>
                        </tr>
                        <tr>
                            <th>ADABOOST <br/>REGRESSOR</th>
                            <td>328924.992</td>
                            <td>573.5198</td>
                            <td>0.79599</td>
                            <td>0.81787</td>
                            <td>-490.6971</td>
                            <td>-416.4971</td>
                            <td>11347.0777</td>
                            <td>10564.2518</td>
                            <td>299322.3796</td>
                            <td>547.1036</td>
                            <td>0.79598</td>
                            <td>0.8287</td>
                            <td>-502.08191</td>
                            <td>-430.282</td>
                            <td>11484.1371</td>
                            <td>10753.506</td>
                        </tr>
                        <tr>
                            <th>XGBOOST <br/>REGRESSOR</th>
                            <td>31231.2846</td>
                            <td>176.7237</td>
                            <td>0.9709</td>
                            <td>0.9827</td>
                            <td>-490.6971</td>
                            <td>-492.1244</td>
                            <td>11347.0777</td>
                            <td>11361.6967</td>
                            <td>38738.9761</td>
                            <td>196.8222</td>
                            <td>0.9709</td>
                            <td>0.97783</td>
                            <td>-502.0819</td>
                            <td>-504.7197</td>
                            <td>11484.1371</td>
                            <td>11520.2366</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <p class="insights-text">
                <br/>
                Top Performers: XGBoost and Gradient Boosting are the standout models, offering the best performance with low error and high RÂ² scores. These models are recommended for deployment.
                <br/>
                Middle Tier Performers: Decision Tree and AdaBoost perform adequately but are not as robust as the top performers.
                <br/>
                Lower Performers: Random Forest, Bagging, KNN, Linear Regressor, and especially SVR underperform relative to the others, with higher errors and lower RÂ² scores. These models might require more tuning or are less suitable for the given data.
            </p>
        </p>
        <p class="insights-text">
            After all the analysis an XgBoost Regressor model has been trained to predict the outcome of the yield when values for clonesize, honeybee, bumbles, andrena, osmia, mean_temp and AverageRainingDays are provided.
            <br/>
            The model gives the following statistics when tested on both training and testing set:
            <br/><br/>
            ***Stats on training data***
            <br/><br/>
            MSE: 31231.284640907303
            <br/>
            RMSE: 176.7237523393709
            <br/>
            Mean Cross Validation Score: 0.9708734221451636
            <br/>
            RÂ² score for : 0.982707026224603
            <br/>
            Slope(actual): -490.69707506176667 and intercept(actual): 11347.077703538986
            <br/>
            Slope(pred): -492.12439871300916 and intercept(pred): 11361.696721633403
            <br/><br/>
            *** Stats on testing data***
            <br/><br/>
            MSE: 38738.97611930207
            <br/>
            RMSE: 196.82219417357908
            <br/>
            Mean Cross Validation Score: 0.9708734221451636
            <br/>
            RÂ² score for : 0.977830747884851
            <br/>
            Slope(actual): -502.0819097212534 and intercept(actual): 11484.13713732688
            <br/>
            Slope(pred): -504.71968536936816 and intercept(pred): 11520.236596340059
            <div class="charts-row">
                <div class="chart-column">
                <img src="../static/images/xgb_output.png" alt="Chart showing data distribution" class="chart-image" id="hash-chart"/>
                </div>
            </div>
        </p>
        <p class="insights-text">
            17. Analysis :
            <br/>
            1. RMSE: The RMSE for the training data (176.72) and the testing data (196.82) indicate the model's performance. The RMSE for the testing data is higher, which is expected as models generally perform better on training data.
            <br/>
            2. RÂ² Score: The RÂ² scores for both training (0.9827) and testing (0.9778) data are high, suggesting that the model explains a large proportion of the variance in the data.
            <br/>
            3. Mean Cross Validation Score: The mean cross-validation score (0.9709) is consistent between training and testing data, indicating that the model generalizes well.
            <br/>
            4. Slope and Intercept: There's a slight difference between the slopes and intercepts of actual versus predicted values, but overall, the model seems to perform consistently on both sets of data.
        </p>
        <p class="insights-text">
            <br/><br/>
            Final thoughts:
            <br/><br/>
            1. The dataset is slightly problematic as few features which are supposed to be related to each other are not related at all.
            <br/>
            2. This might be the result of the dataset being generated by an artificial simulation environment and not collection of data from natural sources.
            <br/>
            3. The performance of the model may be improved further if more extensive data is present and fed to the model to let the model understand the underlying patterns well.
            <br/>
            4. However for now RMSE of 196.82 and R2 score of 0.9778 is achieved and the model is performing fairly well to predict values close to the original values.
        </p>
        </article>
        </div>
    </section>
</body>
</html>
